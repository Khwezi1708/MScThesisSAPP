{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f136a04",
   "metadata": {},
   "source": [
    "This file will run an LSTM model to predict the electricity prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03c0053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import plot_comparison, evaluate_lstm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a92140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data/zra_sgp_dam.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.set_index('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0032cb70",
   "metadata": {},
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61e6a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cyclic(df, col, max_val):\n",
    "    \"\"\"\"\n",
    "    Time features like Hour, Month, day_of_week are cyclical, not linear. \n",
    "    Without encoding them properly, the model will misunderstand their relationships.\n",
    "    \"\"\"\n",
    "    df[col + '_sin'] = np.sin(2 * np.pi * df[col] / max_val)\n",
    "    df[col + '_cos'] = np.cos(2 * np.pi * df[col] / max_val)\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Cyclic encode time features\n",
    "    df = encode_cyclic(df, 'Hour', 24)\n",
    "    df = encode_cyclic(df, 'Month', 12)\n",
    "    df = encode_cyclic(df, 'day_of_week', 7)\n",
    "    \n",
    "    # Drop unused or problematic columns\n",
    "    df = df.drop(columns=['Hour', 'Month', 'day_of_week'])  # Keep cyclic versions instead\n",
    "    \n",
    "    # Fill/clean if needed\n",
    "    df = df.fillna(method='ffill').dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96285121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequence for LSTM\n",
    "def create_sequences(data, target_col, n_steps=48, forecast_horizon=24):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps - forecast_horizon):\n",
    "        seq_x = data.iloc[i:i+n_steps].drop(columns=[target_col]).values\n",
    "        seq_y = data.iloc[i+n_steps:i+n_steps+forecast_horizon][target_col].values\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61e10133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "class PriceDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7508771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Lstm model\n",
    "class LSTMForecast(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, dropout=0.2, output_size=24):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout if num_layers > 1 else 0.0, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.lstm(x) # Get all outputs\n",
    "        out = output[:, -1, :] # Use output from the last timestep\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e8b35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LogCoshLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss = torch.log(torch.cosh(y_pred - y_true + 1e-12))  # added epsilon to prevent log(0)\n",
    "        return torch.mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9584fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "\n",
    "def train_model(model, dataloader, val_dataloader=None, epochs=10, lr=1e-3, patience=10, min_delta=1e-4):\n",
    "    device = next(model.parameters()).device\n",
    "    criterion = LogCoshLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = copy.deepcopy(model.state_dict())\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for xb, yb in dataloader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        loss_history.append(avg_loss)\n",
    "\n",
    "        if val_dataloader:\n",
    "            model.eval()\n",
    "            val_total_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_dataloader:\n",
    "                    xb, yb = xb.to(device), yb.to(device)\n",
    "                    pred = model(xb)\n",
    "                    loss = criterion(pred, yb)\n",
    "                    val_total_loss += loss.item()\n",
    "\n",
    "            avg_val_loss = val_total_loss / len(val_dataloader)\n",
    "            val_loss_history.append(avg_val_loss)\n",
    "\n",
    "            if best_val_loss - avg_val_loss > min_delta:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"⏹️ Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    if val_dataloader:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    return loss_history, val_loss_history if val_dataloader else loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "556c9c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(loss_history):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(loss_history, label='Training loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Loss per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f56ff6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shap_importance(importances, feature_names=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    names = list(feature_names) if feature_names is not None else [f\"Feature {i}\" for i in range(len(importances))]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(range(len(importances)), importances[indices])\n",
    "    plt.xticks(range(len(importances)), [names[i] for i in indices], rotation=45, ha='right')\n",
    "    plt.title(\"SHAP Feature Importance (Averaged)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4f5eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_datetime(model, df, timestamp, n_steps=48, target_col='Price (USD/MWh)', scaler_y=None):\n",
    "    \"\"\"\n",
    "    Predict 24-hour prices starting from a given timestamp.\n",
    "\n",
    "    Args:\n",
    "        model: Trained LSTMForecast model.\n",
    "        df: Preprocessed + scaled DataFrame (with DateTime index).\n",
    "        timestamp: Datetime string or pd.Timestamp (e.g. '2023-01-01 00:00').\n",
    "        n_steps: Number of past hours to use (default = 48).\n",
    "        target_col: Name of target column.\n",
    "        scaler_y: Scaler used for the target column.\n",
    "\n",
    "    Returns:\n",
    "        List of (datetime, predicted_price) tuples.\n",
    "    \"\"\"\n",
    "    if isinstance(timestamp, str):\n",
    "        timestamp = pd.Timestamp(timestamp)\n",
    "        \n",
    "    # Check if enough history is available\n",
    "    start_idx = df.index.get_loc(timestamp)\n",
    "    if start_idx < n_steps:\n",
    "        raise ValueError(\"Not enough history before this timestamp.\")\n",
    "\n",
    "    # Build the input sequence (excluding target columns)\n",
    "    seq_df = df.iloc[start_idx - n_steps:start_idx].drop(columns=[target_col, 'target_scaled'])\n",
    "    seq_input = seq_df.values  # shape: (n_steps, num_features)\n",
    "\n",
    "    # Predict the future prices\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = torch.tensor(seq_input[np.newaxis, :, :], dtype=torch.float32)\n",
    "        y_pred = model(x).squeeze().numpy()  # shape: (forecast_horizon, )\n",
    "\n",
    "    # Reverse scaling (if provided)\n",
    "    if scaler_y is not None:\n",
    "        y_pred_original = scaler_y.inverse_transform(y_pred.reshape(-1, 1))  # Inverse transform predictions\n",
    "        y_pred_original_flat = y_pred_original.flatten()  # Flatten to 1D\n",
    "    else:\n",
    "        y_pred_original_flat = y_pred  # If no scaler, use raw predictions\n",
    "\n",
    "    # Build future timestamps\n",
    "    future_times = [timestamp + pd.Timedelta(hours=i) for i in range(24)]\n",
    "    \n",
    "    return list(zip(future_times, y_pred_original_flat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aed1bc",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7ca40c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch-local/krasmussen.12138935/ipykernel_3082066/4031471906.py:22: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill').dropna()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Preprocess (make sure 'Date' becomes index)\n",
    "df_clean = preprocess(df)\n",
    "\n",
    "# Define target\n",
    "target_col = 'Price (USD/MWh)'\n",
    "features = df_clean.drop(columns=[target_col])\n",
    "target = df_clean[target_col]\n",
    "\n",
    "# Columns by type\n",
    "minmax_cols = ['Tati- normalised output', 'E_Grid (Mw)', 'Revenues (USD)', \n",
    "               'Flow_chavuma', 'Level_kariba', 'Flow_nana']\n",
    "standard_cols = ['Volatility_1 Day', 'Volatility_3 Days', 'Volatility_7 Days', 'Volatility_30 Days',\n",
    "                 'roc_49h', 'momentum_49h']\n",
    "no_scaling_cols = ['Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos',\n",
    "                   'day_of_week_sin', 'day_of_week_cos']\n",
    "\n",
    "# Initialize scalers\n",
    "minmax_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# Copy clean DataFrame\n",
    "df_scaled = df_clean.copy()\n",
    "\n",
    "# Apply scalers to appropriate columns\n",
    "df_scaled[minmax_cols] = minmax_scaler.fit_transform(df_clean[minmax_cols])\n",
    "df_scaled[standard_cols] = standard_scaler.fit_transform(df_clean[standard_cols])\n",
    "\n",
    "# Target scaling (fit only on the column, keep shape)\n",
    "df_scaled[\"target_scaled\"] = scaler_y.fit_transform(df_clean[[target_col]])\n",
    "\n",
    "# Optionally retain unscaled target for reference\n",
    "df_scaled[target_col] = target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e038617",
   "metadata": {},
   "source": [
    "# CNN\n",
    "CNN-based feature extractor before creating sequences for your time series model.\n",
    "Use a 1D CNN to learn temporal features from the multivariate time series, and combine those with your original engineered features (like Fourier features, volatility, etc.) to build an enriched LSTM input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "665894bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels, out_channels=16, kernel_size=5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, out_channels, kernel_size, padding=kernel_size // 2)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size // 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, channels, sequence_length)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        return x  # shape: (batch, out_channels, sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a0b6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_cnn_over_time(df_features, window=48, stride=1, device='cpu'):\n",
    "    \"\"\"\n",
    "    Apply CNN over rolling time windows of multivariate input.\n",
    "    Returns a DataFrame with CNN features per time step (centered).\n",
    "    \"\"\"\n",
    "    feature_cols = df_features.columns\n",
    "    num_features = len(feature_cols)\n",
    "    num_windows = (len(df_features) - window) // stride + 1\n",
    "\n",
    "    # Prepare input tensor\n",
    "    X_cnn = []\n",
    "    for i in range(0, len(df_features) - window + 1, stride):\n",
    "        window_data = df_features.iloc[i:i+window].values.T  # shape: (features, window)\n",
    "        X_cnn.append(window_data)\n",
    "\n",
    "    X_cnn = torch.tensor(np.stack(X_cnn), dtype=torch.float32).to(device)  # shape: (batch, features, window)\n",
    "\n",
    "    # CNN model\n",
    "    cnn = CNNFeatureExtractor(input_channels=num_features).to(device)\n",
    "    cnn.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features_out = cnn(X_cnn)  # shape: (batch, out_channels, window)\n",
    "    \n",
    "    # Collapse time dimension (e.g., take mean over time)\n",
    "    pooled = features_out.mean(dim=2).cpu().numpy()  # shape: (batch, out_channels)\n",
    "\n",
    "    # Align timestamps to center of each window\n",
    "    start_index = window // 2\n",
    "    end_index = start_index + len(pooled)\n",
    "    timestamps = df_features.index[start_index:end_index]\n",
    "\n",
    "    return pd.DataFrame(pooled, index=timestamps, columns=[f'cnn_feat_{i}' for i in range(pooled.shape[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a854f494",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_features_df = apply_cnn_over_time(\n",
    "    df_scaled[minmax_cols + standard_cols + no_scaling_cols],  # all features\n",
    "    window=48,\n",
    "    stride=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3338055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align target with features\n",
    "cnn_features_df[\"target_scaled\"] = df_scaled[\"target_scaled\"].loc[cnn_features_df.index]\n",
    "df_lstm_input = cnn_features_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d876fed3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m lookback = \u001b[32m24\u001b[39m * \u001b[32m60\u001b[39m \u001b[38;5;66;03m# 30 days of history\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Create sequences\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m X, y = \u001b[43mcreate_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_scaled\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPrice (USD/MWh)\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtarget_scaled\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlookback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_horizon\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m24\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Train-validation-test split (70-15-15 split)\u001b[39;00m\n\u001b[32m      6\u001b[39m X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=\u001b[32m0.3\u001b[39m, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mcreate_sequences\u001b[39m\u001b[34m(data, target_col, n_steps, forecast_horizon)\u001b[39m\n\u001b[32m      3\u001b[39m X, y = [], []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data) - n_steps - forecast_horizon):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     seq_x = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.values\n\u001b[32m      6\u001b[39m     seq_y = data.iloc[i+n_steps:i+n_steps+forecast_horizon][target_col].values\n\u001b[32m      7\u001b[39m     X.append(seq_x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/frame.py:5581\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5434\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5435\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5442\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5443\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5444\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5445\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5446\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5579\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5580\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5583\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5587\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5588\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/generic.py:4788\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4786\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4787\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4788\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4791\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/generic.py:4831\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4829\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4830\u001b[39m         new_axis = axis.drop(labels, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m4831\u001b[39m     indexer = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4833\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4834\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4835\u001b[39m     is_tuple_labels = is_nested_list_like(labels) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, \u001b[38;5;28mtuple\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3890\u001b[39m, in \u001b[36mIndex.get_indexer\u001b[39m\u001b[34m(self, target, method, limit, tolerance)\u001b[39m\n\u001b[32m   3887\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) == \u001b[32m0\u001b[39m:\n\u001b[32m   3888\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.array([], dtype=np.intp)\n\u001b[32m-> \u001b[39m\u001b[32m3890\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_partial_index(target):\n\u001b[32m   3891\u001b[39m     \u001b[38;5;66;03m# IntervalIndex get special treatment bc numeric scalars can be\u001b[39;00m\n\u001b[32m   3892\u001b[39m     \u001b[38;5;66;03m#  matched to Interval scalars\u001b[39;00m\n\u001b[32m   3893\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_indexer_non_comparable(target, method=method, unique=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   3895\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.dtype, CategoricalDtype):\n\u001b[32m   3896\u001b[39m     \u001b[38;5;66;03m# _maybe_cast_listlike_indexer ensures target has our dtype\u001b[39;00m\n\u001b[32m   3897\u001b[39m     \u001b[38;5;66;03m#  (could improve perf by doing _should_compare check earlier?)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:6413\u001b[39m, in \u001b[36mIndex._should_compare\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m   6410\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   6412\u001b[39m dtype = _unpack_nested_dtype(other)\n\u001b[32m-> \u001b[39m\u001b[32m6413\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_is_comparable_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:6415\u001b[39m, in \u001b[36mIndex._is_comparable_dtype\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   6412\u001b[39m     dtype = _unpack_nested_dtype(other)\n\u001b[32m   6413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_comparable_dtype(dtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m6415\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_is_comparable_dtype\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: DtypeObj) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m   6416\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   6417\u001b[39m \u001b[33;03m    Can we compare values of the given dtype to our own?\u001b[39;00m\n\u001b[32m   6418\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   6419\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dtype.kind == \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "lookback = 24 * 60 # 30 days of history\n",
    "forecast_horizon = 24\n",
    "\n",
    "# Kernel will crash otherwise due to memory\n",
    "if lookback >= 2160:\n",
    "    total_len = len(df_scaled)\n",
    "    train_end = int(0.7 * total_len)\n",
    "    val_end = int(0.85 * total_len)\n",
    "\n",
    "    df_train = df_scaled.drop(columns=['Price (USD/MWh)']).iloc[:train_end]\n",
    "    df_val = df_scaled.drop(columns=['Price (USD/MWh)']).iloc[train_end:]\n",
    "    df_test = df_scaled.drop(columns=['Price (USD/MWh)']).iloc[val_end:]\n",
    "\n",
    "    train_ds = LazyPriceDataset(df_train, target_col='target_scaled', lookback=lookback, forecast_horizon=forecast_horizon)\n",
    "    val_ds   = LazyPriceDataset(df_val,   target_col='target_scaled', lookback=lookback, forecast_horizon=forecast_horizon)\n",
    "    test_ds  = LazyPriceDataset(df_test,  target_col='target_scaled', lookback=lookback, forecast_horizon=forecast_horizon)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=False, num_workers=0)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False, num_workers=0)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=64, shuffle=False, num_workers=0)\n",
    "    # After creating train_loader (lazy or not)\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    # Create a *dummy* X with the right shape but no data copying\n",
    "    X = torch.empty((len(train_loader.dataset),) + sample_batch[0].shape[1:])\n",
    "\n",
    "else:\n",
    "    # Create sequences\n",
    "    X, y = create_sequences(df_scaled.drop(columns=['Price (USD/MWh)']), target_col='target_scaled', n_steps=lookback, forecast_horizon=24)\n",
    "\n",
    "    # Train-validation-test split (70-15-15 split)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "\n",
    "    # Create datasets\n",
    "    train_ds = PriceDataset(X_train, y_train)\n",
    "    val_ds = PriceDataset(X_val, y_val)\n",
    "    test_ds = PriceDataset(X_test, y_test)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=False, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=64, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d531474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import uniform\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming LSTMForecast and train_ds are defined elsewhere\n",
    "# Also assuming val_loader is defined somewhere\n",
    "\n",
    "input_size = X.shape[2]  # Number of features (should match the input size of the LSTM)\n",
    "\n",
    "class WOA:\n",
    "    def __init__(self, n_whales, max_iter, bounds):\n",
    "        self.n_whales = n_whales\n",
    "        self.max_iter = max_iter\n",
    "        self.bounds = bounds\n",
    "        self.population = self.init_population()\n",
    "        self.best_whale = None\n",
    "        self.best_fitness = float('inf')\n",
    "\n",
    "    def init_population(self):\n",
    "        \"\"\"Initialize whale population randomly within the specified bounds.\"\"\"\n",
    "        population = []\n",
    "        for _ in range(self.n_whales):\n",
    "            whale = [uniform(*self.bounds[param]) for param in self.bounds]\n",
    "            population.append(whale)\n",
    "        return population\n",
    "\n",
    "    def smape(self, y_true, y_pred):\n",
    "        \"\"\"Symmetric Mean Absolute Percentage Error\"\"\"\n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "        smape = np.mean(np.abs(y_pred - y_true) / denominator) * 100\n",
    "        return smape\n",
    "    \n",
    "    def evaluate_model(self, model, val_loader, device):\n",
    "        \"\"\"Evaluate the model on the validation set.\"\"\"\n",
    "        model.to(device)  # Ensure model is on the correct device (GPU or CPU)\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        with torch.no_grad():  # No gradient calculation needed during evaluation\n",
    "            for xb, yb in val_loader:  # Iterate over validation data\n",
    "                xb, yb = xb.to(device), yb.to(device)  # Move data to the correct device\n",
    "                output = model(xb)  # Model's predictions\n",
    "\n",
    "                y_true.append(yb.cpu().numpy())  # Store actual values\n",
    "                y_pred.append(output.cpu().numpy())  # Store predicted values\n",
    "\n",
    "        # Flatten the lists into 1D arrays for easy SMAPE calculation\n",
    "        y_true = np.concatenate(y_true, axis=0)\n",
    "        y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "        return y_true, y_pred\n",
    "\n",
    "    def fitness(self, whale):\n",
    "        \"\"\"Calculate fitness (SMAPE) of the current whale configuration.\"\"\"\n",
    "        hidden_size, num_layers, dropout, lr = whale\n",
    "\n",
    "        N_subset = 8760 - lookback\n",
    "        subset_indices = list(range(N_subset))\n",
    "        subset_train_ds = torch.utils.data.Subset(train_ds, subset_indices)\n",
    "        subset_train_loader = DataLoader(subset_train_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        model = LSTMForecast(\n",
    "            input_size=input_size,\n",
    "            hidden_size=int(hidden_size),\n",
    "            num_layers=int(num_layers),\n",
    "            dropout=dropout,\n",
    "            output_size=24\n",
    "        ).to(device)  # Move the model to the correct device\n",
    "\n",
    "        # Get actuals and predictions from validation\n",
    "        y_true, y_pred = self.evaluate_model(model, val_loader, device)\n",
    "\n",
    "        return self.smape(y_true, y_pred)\n",
    "\n",
    "\n",
    "    def update_position(self, whale, a, best_whale):\n",
    "        \"\"\"Update the position of the whale based on the hunting behavior.\"\"\"\n",
    "        A = 2 * a * np.random.rand() - a  # Randomization for exploration\n",
    "        C = 2 * np.random.rand()  # Another randomization factor for exploration\n",
    "        p = np.random.rand()  # Probability for exploitation or exploration\n",
    "\n",
    "        if p < 0.5:\n",
    "            if np.abs(A) >= 1:\n",
    "                # Exploration: Random movement\n",
    "                rand_whale = self.population[np.random.randint(self.n_whales)]\n",
    "                new_whale = np.array(rand_whale) - A * np.abs(C * np.array(rand_whale) - np.array(whale))\n",
    "            else:\n",
    "                # Exploitation: Move towards best whale\n",
    "                new_whale = np.array(best_whale) - A * np.abs(C * np.array(best_whale) - np.array(whale))\n",
    "        else:\n",
    "            distance_best = np.abs(np.array(best_whale) - np.array(whale))\n",
    "            new_whale = distance_best * np.exp(a * distance_best) * np.cos(2 * np.pi * np.random.rand())\n",
    "\n",
    "        # Bound check: Ensure the new whale is within bounds\n",
    "        new_whale = np.clip(new_whale, [self.bounds[param][0] for param in self.bounds],\n",
    "                            [self.bounds[param][1] for param in self.bounds])\n",
    "        \n",
    "        return new_whale\n",
    "\n",
    "    def optimize(self, smape_threshold=10.0):\n",
    "        \"\"\"Run the Whale Optimization Algorithm.\"\"\"\n",
    "        for t in tqdm(range(self.max_iter), desc=\"WOA Iterations\"):\n",
    "            a = 2 - t * (2 / self.max_iter)\n",
    "\n",
    "            for i in tqdm(range(self.n_whales), desc=f\"Whales (Iteration {t+1})\", leave=False):\n",
    "                whale = self.population[i]\n",
    "                hidden_size, num_layers, dropout, lr = whale\n",
    "\n",
    "                # print(f\"Iteration {t+1}, Whale {i+1}: hidden_size={int(hidden_size)}, \"\n",
    "                #       f\"num_layers={int(num_layers)}, dropout={dropout:.3f}, lr={lr:.6f}\")\n",
    "\n",
    "                fitness_val = self.fitness(whale)\n",
    "\n",
    "                if fitness_val < self.best_fitness:\n",
    "                    self.best_fitness = fitness_val\n",
    "                    self.best_whale = whale\n",
    "\n",
    "                    # Early stopping if precision threshold met\n",
    "                    if self.best_fitness <= smape_threshold:\n",
    "                        # print(f\"\\nStopping early at iteration {t+1} with SMAPE {self.best_fitness:.2f}\")\n",
    "                        return self.best_whale, self.best_fitness\n",
    "\n",
    "                self.population[i] = self.update_position(whale, a, self.best_whale)\n",
    "\n",
    "        return self.best_whale, self.best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50bb30de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WOA Iterations: 100%|██████████| 50/50 [25:53<00:00, 31.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best configuration from WOA:\n",
      "Best Params: [2.56000000e+02 1.72764837e+00 5.00000000e-01 2.32974311e-03]\n",
      "Best Validation Loss: 119.81548070907593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the bounds for the hyperparameters\n",
    "bounds = {\n",
    "    'hidden_size': (32, 256),  # Increased hidden size range to 256\n",
    "    'num_layers': (1, 4),      # Increased num_layers range to 4\n",
    "    'dropout': (0.1, 0.5),     # Increased dropout range to 0.5\n",
    "    'lr': (5e-4, 1e-2)         # Increased learning rate range to 1e-2\n",
    "}\n",
    "\n",
    "# Create the WOA optimizer with the updated bounds\n",
    "woa = WOA(n_whales=10, max_iter=50, bounds=bounds)\n",
    "# Run optimization\n",
    "best_params, best_val_loss = woa.optimize()\n",
    "\n",
    "# Output the best found parameters and corresponding validation loss\n",
    "print(\"\\nBest configuration from WOA:\")\n",
    "print(f\"Best Params: {best_params}\")\n",
    "print(f\"Best Validation Loss: {best_val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba8d58eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed in 6139.98 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"Train model with best params from WOA\"\n",
    "import time  # Add this at the top of your script if not already imported\n",
    "# Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size = X.shape[2]  # Number of features (should match the input size of the LSTM)\n",
    "\n",
    "model = LSTMForecast(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(256),  # Ensure integer value for hidden_size\n",
    "    num_layers=int(2),   # Ensure integer value for num_layers\n",
    "    dropout=best_params[2]\n",
    ").to(device)\n",
    "\n",
    "# Train the model with timing\n",
    "start_time = time.time()\n",
    "\n",
    "train_losses, val_losses = train_model(\n",
    "    model,\n",
    "    dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    "    epochs=100,\n",
    "    lr=best_params[3],\n",
    "    patience=15,       # stop if no val improvement\n",
    "    min_delta=1e-4     # must improve by at least this much\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nTraining completed in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "plot_loss(train_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36af78dd",
   "metadata": {},
   "source": [
    "# Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e99e5520",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 2160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bed66e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_val_preds, y_val_true = [], []\n",
    "y_test_preds, y_test_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    if lookback >= 2160:\n",
    "        # Lazy: batch-by-batch prediction\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            preds = model(xb)\n",
    "            y_val_preds.append(preds.cpu())\n",
    "            y_val_true.append(yb.cpu())\n",
    "\n",
    "        for xb, yb in test_loader:\n",
    "            xb = xb.to(device)\n",
    "            preds = model(xb)\n",
    "            y_test_preds.append(preds.cpu())\n",
    "            y_test_true.append(yb.cpu())\n",
    "\n",
    "        y_val_pred = torch.cat(y_val_preds).numpy()\n",
    "        y_val = torch.cat(y_val_true).numpy()\n",
    "        y_test_pred = torch.cat(y_test_preds).numpy()\n",
    "        y_test = torch.cat(y_test_true).numpy()\n",
    "\n",
    "    else:\n",
    "        # Eager mode\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "        y_val_pred = model(X_val_tensor).cpu().numpy()\n",
    "        y_test_pred = model(X_test_tensor).cpu().numpy()\n",
    "\n",
    "# Reverse scaling\n",
    "y_val_pred_original = scaler_y.inverse_transform(y_val_pred)\n",
    "y_test_pred_original = scaler_y.inverse_transform(y_test_pred)\n",
    "\n",
    "y_val_original = scaler_y.inverse_transform(y_val.reshape(-1, 1))\n",
    "y_test_original = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Flatten\n",
    "y_val_pred_original_flat = y_val_pred_original.flatten()\n",
    "y_test_pred_original_flat = y_test_pred_original.flatten()\n",
    "y_val_flat = y_val_original.flatten()\n",
    "y_test_flat = y_test_original.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0c0a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reverse scaling for the 24-hour forecast predictions (after prediction)\n",
    "# y_val_pred_original = scaler_y.inverse_transform(y_val_pred.detach().cpu().numpy())\n",
    "# y_test_pred_original = scaler_y.inverse_transform(y_test_pred.detach().cpu().numpy())\n",
    "# # Flatten the predictions to 1D\n",
    "# y_val_pred_original_flat = y_val_pred_original.flatten()  # Flatten to 1D\n",
    "# y_test_pred_original_flat = y_test_pred_original.flatten()  # Flatten to 1D\n",
    "\n",
    "# # Reverse scaling of actual values (if needed)\n",
    "# y_val_original = scaler_y.inverse_transform(y_val.reshape(-1, 1))  # Reverse scaling for true values\n",
    "# y_test_original = scaler_y.inverse_transform(y_test.reshape(-1, 1))  # Reverse scaling for true values\n",
    "\n",
    "# # Flatten the true values\n",
    "# y_val_flat = y_val_original.flatten()\n",
    "# y_test_flat = y_test_original.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0acf0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf871081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datetime index from original DataFrame\n",
    "start_date = df.index.min()\n",
    "end_date = df.index.max()\n",
    "all_datetimes = pd.date_range(start=start_date, end=end_date, freq='h')\n",
    "N_total = len(all_datetimes)\n",
    "\n",
    "# Recalculate split indices\n",
    "train_size = int(0.7 * N_total)\n",
    "val_size = int(0.15 * N_total)\n",
    "val_start = train_size\n",
    "val_end = train_size + val_size\n",
    "test_start = val_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16fd2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate datetime index for predictions\n",
    "val_index_expanded = pd.date_range(start=all_datetimes[val_start], periods=len(y_val_flat), freq='h')\n",
    "test_index_expanded = pd.date_range(start=all_datetimes[test_start], periods=len(y_test_flat), freq='h')\n",
    "\n",
    "# Create DataFrames for evaluation\n",
    "X_val_df = pd.DataFrame(index=val_index_expanded)\n",
    "X_test_df = pd.DataFrame(index=test_index_expanded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4e722ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_predictions(\n",
    "    y_true, y_pred, df_index,\n",
    "    start_time=\"2023-08-01 00:00:00\",\n",
    "    n_hours=500,\n",
    "    error_threshold=15\n",
    "):\n",
    "    # Convert inputs\n",
    "    start_time = pd.to_datetime(start_time)\n",
    "\n",
    "    # Build aligned DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'actual': y_true,\n",
    "        'predicted': y_pred\n",
    "    }, index=pd.to_datetime(df_index))\n",
    "\n",
    "    # Slice the time range\n",
    "    df_slice = df.loc[start_time : start_time + pd.Timedelta(hours=n_hours)]\n",
    "\n",
    "    # Calculate error\n",
    "    df_slice['error'] = abs(df_slice['actual'] - df_slice['predicted'])\n",
    "\n",
    "    # Identify high error regions\n",
    "    high_error_mask = df_slice['error'] > error_threshold\n",
    "\n",
    "    # Create Plotly figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Actual values (Deep blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_slice.index, y=df_slice['actual'],\n",
    "        mode='lines', name='True',\n",
    "        line=dict(color='#1f77b4', width=2)\n",
    "    ))\n",
    "\n",
    "    # Predicted values (Soft green)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_slice.index, y=df_slice['predicted'],\n",
    "        mode='lines', name='Predicted',\n",
    "        line=dict(color='#2ca02c', width=2)\n",
    "    ))\n",
    "\n",
    "    # High-error markers (Bold red)\n",
    "    if high_error_mask.any():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_slice.index[high_error_mask],\n",
    "            y=df_slice['predicted'][high_error_mask],\n",
    "            mode='markers',\n",
    "            marker=dict(size=6, color='#d62728', symbol='circle'),\n",
    "            name=f'Error > {error_threshold}',\n",
    "            text=[f\"Error: {e:.2f}\" for e in df_slice['error'][high_error_mask]],  # Hover text\n",
    "            hoverinfo='text+x+y',\n",
    "            showlegend=True\n",
    "        ))\n",
    "\n",
    "    # Layout styling\n",
    "    fig.update_layout(\n",
    "        title=f\"LSTM Forecast from {start_time.strftime('%Y-%m-%d %H:%M')} ({n_hours} hours)\",\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Value\",\n",
    "        template=\"plotly_white\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    "        height=500,\n",
    "        margin=dict(l=40, r=40, t=60, b=40)\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61bd73d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_predictions(\n",
    "#     y_true=y_val_flat,\n",
    "#     y_pred=recon_val_flat,  # Use the reconstructed, inverse-scaled prediction\n",
    "#     df_index=X_val_df.index,  # Assuming you have this aligned with y_val\n",
    "#     start_time=\"2023-08-01 00:00:00\",\n",
    "#     n_hours=500\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56c0d771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Metric        MAE        DAE       RMSE        R2  \\\n",
      "0  Validation Set  43.375629  30.410595  62.934948  0.402182   \n",
      "1        Test Set  74.051094  67.344421  94.665107 -0.201331   \n",
      "\n",
      "   Lower Predictions (%)  \n",
      "0              47.855816  \n",
      "1              82.543076  \n"
     ]
    }
   ],
   "source": [
    "# --- Evaluate model ---\n",
    "results = evaluate_lstm(\n",
    "    y_val=y_val_flat,\n",
    "    y_val_pred=y_val_pred_original_flat,\n",
    "    y_test=y_test_flat,\n",
    "    y_test_pred=y_test_pred_original_flat,\n",
    "    X_val=X_val_df,\n",
    "    X_test=X_test_df)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36114238",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recon_val_flat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, root_mean_squared_error\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m mae = mean_absolute_error(y_val_flat, \u001b[43mrecon_val_flat\u001b[49m)\n\u001b[32m      4\u001b[39m rmse = root_mean_squared_error(y_val_flat, recon_val_flat)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'recon_val_flat' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(y_val_flat, recon_val_flat)\n",
    "rmse = root_mean_squared_error(y_val_flat, recon_val_flat)\n",
    "\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d202f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_datetime(model, df, timestamp, n_steps=48, target_col='Price (USD/MWh)', scaler_y=None):\n",
    "    \"\"\"\n",
    "    Predict 24-hour prices starting from a given timestamp.\n",
    "\n",
    "    Args:\n",
    "        model: Trained LSTMForecast model.\n",
    "        df: Preprocessed + scaled DataFrame (with DateTime index).\n",
    "        timestamp: Datetime string or pd.Timestamp (e.g. '2023-01-01 00:00').\n",
    "        n_steps: Number of past hours to use (default = 48).\n",
    "        target_col: Name of target column.\n",
    "        scaler_y: Scaler used for the target column.\n",
    "\n",
    "    Returns:\n",
    "        List of (datetime, predicted_price) tuples.\n",
    "    \"\"\"\n",
    "    if isinstance(timestamp, str):\n",
    "        timestamp = pd.Timestamp(timestamp)\n",
    "        \n",
    "    # Check if enough history is available\n",
    "    start_idx = df.index.get_loc(timestamp)\n",
    "    if start_idx < n_steps:\n",
    "        raise ValueError(\"Not enough history before this timestamp.\")\n",
    "\n",
    "    # Build the input sequence (excluding target columns)\n",
    "    seq_df = df.iloc[start_idx - n_steps:start_idx].drop(columns=[target_col, 'target_scaled'])\n",
    "    seq_input = seq_df.values  # shape: (n_steps, num_features)\n",
    "\n",
    "    # Predict the future prices\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = torch.tensor(seq_input[np.newaxis, :, :], dtype=torch.float32)\n",
    "        y_pred = model(x).squeeze().numpy()  # shape: (forecast_horizon, )\n",
    "\n",
    "    # Reverse scaling (if provided)\n",
    "    if scaler_y is not None:\n",
    "        y_pred_original = scaler_y.inverse_transform(y_pred.reshape(-1, 1))  # Inverse transform predictions\n",
    "        y_pred_original_flat = y_pred_original.flatten()  # Flatten to 1D\n",
    "    else:\n",
    "        y_pred_original_flat = y_pred  # If no scaler, use raw predictions\n",
    "\n",
    "    # Build future timestamps\n",
    "    future_times = [timestamp + pd.Timedelta(hours=i) for i in range(24)]\n",
    "    \n",
    "    return list(zip(future_times, y_pred_original_flat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25fe44",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 37, got 33",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[132]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m preds = \u001b[43mpredict_from_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2024-01-01 00:00\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mscaler_y\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaler_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t, price \u001b[38;5;129;01min\u001b[39;00m preds:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: $\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprice\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[131]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mpredict_from_datetime\u001b[39m\u001b[34m(model, df, timestamp, n_steps, target_col, scaler_y)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     31\u001b[39m     x = torch.tensor(seq_input[np.newaxis, :, :], dtype=torch.float32)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     y_pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m.squeeze().numpy()  \u001b[38;5;66;03m# shape: (forecast_horizon, )\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Reverse scaling (if provided)\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m scaler_y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mWT_LSTMForecast.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     lstm_out, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, seq_len, hidden_size]\u001b[39;00m\n\u001b[32m     21\u001b[39m     lstm_out = lstm_out[:, -\u001b[38;5;28mself\u001b[39m.forecast_horizon:, :]  \u001b[38;5;66;03m# Slicing to get the last 'forecast_horizon' time steps\u001b[39;00m\n\u001b[32m     22\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.fc(lstm_out)  \u001b[38;5;66;03m# [batch, forecast_horizon, output_dim]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1101\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1093\u001b[39m     c_zeros = torch.zeros(\n\u001b[32m   1094\u001b[39m         \u001b[38;5;28mself\u001b[39m.num_layers * num_directions,\n\u001b[32m   1095\u001b[39m         max_batch_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1098\u001b[39m         device=\u001b[38;5;28minput\u001b[39m.device,\n\u001b[32m   1099\u001b[39m     )\n\u001b[32m   1100\u001b[39m     hx = (h_zeros, c_zeros)\n\u001b[32m-> \u001b[39m\u001b[32m1101\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1002\u001b[39m, in \u001b[36mLSTM.check_forward_args\u001b[39m\u001b[34m(self, input, hidden, batch_sizes)\u001b[39m\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_forward_args\u001b[39m(\n\u001b[32m    997\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    998\u001b[39m     \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[32m    999\u001b[39m     hidden: \u001b[38;5;28mtuple\u001b[39m[Tensor, Tensor],  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m   1000\u001b[39m     batch_sizes: Optional[Tensor],\n\u001b[32m   1001\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1002\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1003\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_hidden_size(\n\u001b[32m   1004\u001b[39m         hidden[\u001b[32m0\u001b[39m],\n\u001b[32m   1005\u001b[39m         \u001b[38;5;28mself\u001b[39m.get_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[32m   1006\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1007\u001b[39m     )\n\u001b[32m   1008\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_hidden_size(\n\u001b[32m   1009\u001b[39m         hidden[\u001b[32m1\u001b[39m],\n\u001b[32m   1010\u001b[39m         \u001b[38;5;28mself\u001b[39m.get_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[32m   1011\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1012\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/rnn.py:314\u001b[39m, in \u001b[36mRNNBase.check_input\u001b[39m\u001b[34m(self, input, batch_sizes)\u001b[39m\n\u001b[32m    310\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    311\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    312\u001b[39m     )\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.input_size != \u001b[38;5;28minput\u001b[39m.size(-\u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    315\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.input_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.size(-\u001b[32m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    316\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: input.size(-1) must be equal to input_size. Expected 37, got 33"
     ]
    }
   ],
   "source": [
    "# preds = predict_from_datetime(model, df_scaled, '2024-01-01 00:00',scaler_y=scaler_y)\n",
    "\n",
    "# for t, price in preds:\n",
    "#     print(f\"{t}: ${price:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984f399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd979aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6a6b6a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8df8b64c",
   "metadata": {},
   "source": [
    "#  Post-Hoc Interpretability with Integrated Gradients (XAI)\n",
    "To understand how the LSTM model arrives at its predictions, we apply post-hoc interpretability methods—techniques used after model training to explain behavior without altering the model itself. One such method is Integrated Gradients, which attributes importance scores to input features based on their contribution to a specific prediction. This approach is particularly valuable for complex, black-box models like LSTMs, where internal mechanisms are not easily interpretable. By applying Integrated Gradients, we gain insights into both individual decisions (local interpretation) and broader model behavior (global interpretation), helping to build transparency, trust, and accountability in the forecasting process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc6c26b",
   "metadata": {},
   "source": [
    "## Local Interpretation\n",
    "The local interpretation using Integrated Gradients provides insight into which input features most influenced the model’s prediction for a specific timestamp. By attributing importance values to each feature in that one sample, we can understand the direction (positive or negative) and magnitude of their impact on the predicted price. This helps explain the model's reasoning at an individual decision level — for example, highlighting that high 7-day volatility or weekend timing pushed the forecast upward in that particular context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "167851ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Mismatch between feature count and column names!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# --- Match feature names to X_val's input dimensions ---\u001b[39;00m\n\u001b[1;32m     10\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m df_lstm_input\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcA_3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcD_3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcD_2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcD_1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m X_val\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(feature_names), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch between feature count and column names!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# --- Disable cuDNN for RNN + IG compatibility ---\u001b[39;00m\n\u001b[1;32m     14\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Mismatch between feature count and column names!"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "# --- Make sure your model is in evaluation mode ---\n",
    "model.eval()\n",
    "\n",
    "# --- Match feature names to X_val's input dimensions ---\n",
    "feature_names = df_lstm_input.columns.drop(['cA_3', 'cD_3', 'cD_2', 'cD_1'])\n",
    "assert X_val.shape[2] == len(feature_names), \"Mismatch between feature count and column names!\"\n",
    "\n",
    "# --- Disable cuDNN for RNN + IG compatibility ---\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "# --- Initialize Integrated Gradients ---\n",
    "ig = IntegratedGradients(model)\n",
    "output_dims = 4  # cA3, cD3, cD2, cD1\n",
    "time_step = 0    # Forecast timestep to evaluate (e.g. first timestep of forecast horizon)\n",
    "\n",
    "all_attributions = []\n",
    "\n",
    "# Loop over validation samples\n",
    "for i in range(len(X_val)):\n",
    "    input_tensor = torch.tensor(X_val[i:i+1], dtype=torch.float32, requires_grad=True).to(next(model.parameters()).device)\n",
    "\n",
    "    sample_attr = []\n",
    "\n",
    "    # Compute attribution for each of the 4 wavelet coefficients\n",
    "    for coeff_idx in range(output_dims):\n",
    "        model.train()  # Enables backward path through LSTM\n",
    "        attr = ig.attribute(\n",
    "            input_tensor,\n",
    "            target=(time_step, coeff_idx),\n",
    "            return_convergence_delta=False\n",
    "        )\n",
    "        model.eval()\n",
    "\n",
    "        # Sum over time dimension to collapse into (features,)\n",
    "        attr = attr.sum(dim=1).squeeze().detach().cpu().numpy()\n",
    "        sample_attr.append(attr)\n",
    "\n",
    "    # Stack attributions: shape (4, num_features)\n",
    "    sample_attr = np.stack(sample_attr)\n",
    "    all_attributions.append(sample_attr)\n",
    "\n",
    "# Re-enable cuDNN\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "# --- Aggregate attributions ---\n",
    "# Shape: (num_samples, 4, num_features)\n",
    "all_attr = np.stack(all_attributions)\n",
    "\n",
    "# Global average over all wavelet outputs and all samples\n",
    "avg_attr = np.mean(all_attr, axis=(0, 1))  # shape: (num_features,)\n",
    "\n",
    "# --- Plot global feature importance ---\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(feature_names, avg_attr)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel(\"Average Attribution\")\n",
    "plt.title(\"Global Feature Importance (Averaged over Coefficients and Samples)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ee1e07",
   "metadata": {},
   "source": [
    "The global interpretation aggregates feature attributions across many samples to show which inputs the model relies on most consistently. By averaging importance scores, it highlights the overall influence of each feature on predictions—revealing patterns such as persistent reliance on long-term volatility or cyclical time features. This offers a high-level understanding of the model’s behavior and helps validate that it aligns with domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552cd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attributions = []\n",
    "model.eval()\n",
    "\n",
    "for i in range(len(X_val)):\n",
    "    input_tensor = torch.tensor(X_val[i:i+1], dtype=torch.float32, requires_grad=True)\n",
    "    attributions, _ = ig.attribute(input_tensor, target=0, return_convergence_delta=True)\n",
    "    summed = attributions.sum(dim=1).squeeze().detach().numpy()\n",
    "    all_attributions.append(summed)\n",
    "\n",
    "# Now average across all samples\n",
    "avg_attr = np.mean(np.stack(all_attributions), axis=0)\n",
    "\n",
    "# Plot global feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(feature_names, avg_attr)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel(\"Average Attribution\")\n",
    "plt.title(\"Global Feature Importance via Integrated Gradients\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
