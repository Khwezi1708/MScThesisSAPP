{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43a0c8ec",
   "metadata": {},
   "source": [
    "In this file, the LEAR (Lagged Error Auto-Regressive) model will be applied to forecast the price based on historical price data. This serves as a benchmark model to evaluate the performance of other more complex forecasting methods. The LEAR model will use the historical data to predict future prices and assess its effectiveness in capturing trends and fluctuations in the pricing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b376668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from functions import plot_comparison, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ad8cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data/zra_sgp_dam.csv')\n",
    "\n",
    "# Convert the 'Date' column to datetime if it's not already\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "# Set the Date column as index\n",
    "df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de0bb8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate lag features\n",
    "df['price_lag30d'] = df['Price (USD/MWh)'].shift(24*30)\n",
    "df['price_lag30d'] = df['price_lag30d'].fillna(df['Price (USD/MWh)'])  # Fill with actual price for 30-day lag\n",
    "\n",
    "df['price_lag60d'] = df['Price (USD/MWh)'].shift(24*60)\n",
    "df['price_lag60d'] = df['price_lag60d'].fillna(df['Price (USD/MWh)'])  # Fill with actual price for 60-day lag\n",
    "\n",
    "df['price_lag90d'] = df['Price (USD/MWh)'].shift(24*90)\n",
    "df['price_lag90d'] = df['price_lag90d'].fillna(df['Price (USD/MWh)'])  # Fill with actual price for 90-day lag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abde991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def encode_cyclic(df, col, max_val):\n",
    "    \"\"\"\"\n",
    "    Time features like Hour, Month, day_of_week are cyclical, not linear. \n",
    "    Without encoding them properly, the model will misunderstand their relationships.\n",
    "    \"\"\"\n",
    "    df[col + '_sin'] = np.sin(2 * np.pi * df[col] / max_val)\n",
    "    df[col + '_cos'] = np.cos(2 * np.pi * df[col] / max_val)\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Cyclic encode time features\n",
    "    df = encode_cyclic(df, 'Hour', 24)\n",
    "    df = encode_cyclic(df, 'Month', 12)\n",
    "    df = encode_cyclic(df, 'day_of_week', 7)\n",
    "    \n",
    "    # Drop unused or problematic columns\n",
    "    df = df.drop(columns=['Hour', 'Month', 'day_of_week'])  # Keep cyclic versions instead\n",
    "    \n",
    "    # Fill/clean if needed\n",
    "    df = df.fillna(method='ffill').dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    # Directional accuracy (compare sign of changes)\n",
    "    true_diff = np.diff(y_true)\n",
    "    pred_diff = np.diff(y_pred)\n",
    "    dae = np.mean(np.sign(true_diff) == np.sign(pred_diff))\n",
    "\n",
    "    lower_pct = np.mean(y_pred < y_true) * 100\n",
    "    return mae, rmse, r2, dae, lower_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c68cb34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch-local/krasmussen.12594015/ipykernel_3686790/424768561.py:23: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill').dropna()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Preprocess (make sure 'Date' becomes index)\n",
    "df_clean = preprocess(df)\n",
    "\n",
    "# Define target\n",
    "target_col = 'Price (USD/MWh)'\n",
    "features = df_clean.drop(columns=[target_col])\n",
    "target = df_clean[target_col]\n",
    "\n",
    "# Columns by type\n",
    "minmax_cols = ['Tati- normalised output', 'E_Grid (Mw)', 'Revenues (USD)', \n",
    "               'Flow_chavuma', 'Level_kariba', 'Flow_nana']\n",
    "standard_cols = ['Volatility_1 Day', 'Volatility_3 Days', 'Volatility_7 Days', 'Volatility_30 Days',\n",
    "                 'roc_49h', 'momentum_49h']\n",
    "no_scaling_cols = ['Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos',\n",
    "                   'day_of_week_sin', 'day_of_week_cos']\n",
    "\n",
    "# Initialize scalers\n",
    "minmax_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# Copy clean DataFrame\n",
    "df_scaled = df_clean.copy()\n",
    "\n",
    "# Apply scalers to appropriate columns\n",
    "df_scaled[minmax_cols] = minmax_scaler.fit_transform(df_clean[minmax_cols])\n",
    "df_scaled[standard_cols] = standard_scaler.fit_transform(df_clean[standard_cols])\n",
    "\n",
    "# Target scaling (fit only on the column, keep shape)\n",
    "df_scaled[\"target_scaled\"] = scaler_y.fit_transform(df_clean[[target_col]])\n",
    "\n",
    "# Optionally retain unscaled target for reference\n",
    "df_scaled[target_col] = target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4005b731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch-local/krasmussen.12594015/ipykernel_3686790/424768561.py:23: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill').dropna()\n",
      "/scratch-local/krasmussen.12594015/ipykernel_3686790/2773569774.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col_name].fillna(df_clean['Price (USD/MWh)'], inplace=True)  # fill initial NAs with current price\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "\n",
    "# --- Preprocessing (assume preprocess function is defined) ---\n",
    "df_clean = preprocess(df)  # make sure 'Date' is index in this step\n",
    "\n",
    "# Create lag features upfront (assume hourly data, 24 per day)\n",
    "lags_days = [7, 30, 60, 90]\n",
    "for lag in lags_days:\n",
    "    col_name = f'price_lag{lag}d'\n",
    "    df_clean[col_name] = df_clean['Price (USD/MWh)'].shift(24*lag)\n",
    "    df_clean[col_name].fillna(df_clean['Price (USD/MWh)'], inplace=True)  # fill initial NAs with current price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41926544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "% Validation Results (Lookback: 7 days)\n",
      " & 7 & 0.06 & 0.67 & 1.00 & 0.10 & 0.75 & 41.72 \\\\\n",
      "% Test Results (Lookback: 7 days)\n",
      " & 7 & 0.07 & 0.63 & 1.00 & 0.11 & 0.76 & 40.53 \\\\\n",
      "\n",
      "Non-zero coefficients (Lookback: 7 days):\n",
      "price_lag7d: 0.0013\n",
      "price_lag1d: 0.0005\n",
      "ema_22h: 0.0004\n",
      "price_lag14d: 0.0004\n",
      "ema_168h: -0.0000\n",
      "GlobHor (W/m²): -0.0000\n",
      "EArray (kW): 0.0000\n",
      "E_Grid (kW): -0.0000\n",
      "\n",
      "% Validation Results (Lookback: 30 days)\n",
      " & 30 & 0.07 & 0.64 & 1.00 & 0.11 & 0.73 & 42.60 \\\\\n",
      "% Test Results (Lookback: 30 days)\n",
      " & 30 & 0.08 & 0.61 & 1.00 & 0.11 & 0.74 & 41.16 \\\\\n",
      "\n",
      "Non-zero coefficients (Lookback: 30 days):\n",
      "price_lag14d: 0.0014\n",
      "price_lag1d: 0.0008\n",
      "ema_22h: 0.0006\n",
      "price_lag30d: -0.0001\n",
      "ema_168h: -0.0001\n",
      "GlobHor (W/m²): -0.0000\n",
      "EArray (kW): 0.0000\n",
      "E_Grid (kW): -0.0000\n",
      "\n",
      "% Validation Results (Lookback: 60 days)\n",
      " & 60 & 0.07 & 0.65 & 1.00 & 0.11 & 0.73 & 41.87 \\\\\n",
      "% Test Results (Lookback: 60 days)\n",
      " & 60 & 0.08 & 0.62 & 1.00 & 0.11 & 0.74 & 38.93 \\\\\n",
      "\n",
      "Non-zero coefficients (Lookback: 60 days):\n",
      "price_lag14d: 0.0014\n",
      "price_lag1d: 0.0008\n",
      "ema_22h: 0.0007\n",
      "ema_168h: -0.0002\n",
      "price_lag60d: 0.0000\n",
      "GlobHor (W/m²): -0.0000\n",
      "EArray (kW): 0.0000\n",
      "E_Grid (kW): -0.0000\n",
      "\n",
      "% Validation Results (Lookback: 90 days)\n",
      " & 90 & 0.07 & 0.65 & 1.00 & 0.10 & 0.74 & 39.73 \\\\\n",
      "% Test Results (Lookback: 90 days)\n",
      " & 90 & 0.08 & 0.63 & 1.00 & 0.11 & 0.75 & 36.60 \\\\\n",
      "\n",
      "Non-zero coefficients (Lookback: 90 days):\n",
      "price_lag14d: 0.0013\n",
      "price_lag1d: 0.0008\n",
      "ema_22h: 0.0007\n",
      "price_lag90d: 0.0002\n",
      "ema_168h: -0.0002\n",
      "GlobHor (W/m²): -0.0000\n",
      "EArray (kW): 0.0000\n",
      "E_Grid (kW): -0.0000\n"
     ]
    }
   ],
   "source": [
    "# Define lag columns as list\n",
    "lag_cols = [f'price_lag{lag}d' for lag in lags_days]\n",
    "\n",
    "# Define base features = all columns except lag columns, target, and target_scaled\n",
    "exclude_cols = lag_cols + [target_col, 'target_scaled']\n",
    "base_feature_cols = [col for col in df_scaled.columns if col not in exclude_cols]\n",
    "\n",
    "results = []\n",
    "lags = []\n",
    "\n",
    "# Loop over lookbacks\n",
    "for lookback in lags_days:\n",
    "    # print(f\"\\n--- Lookback: {lookback} days ---\")\n",
    "    lags.append(lookback)\n",
    "    current_lag = f'price_lag{lookback}d'\n",
    "    if current_lag not in df_scaled.columns:\n",
    "        print(f\"Missing lag column: {current_lag}\")\n",
    "        continue\n",
    "    \n",
    "    # Features = base features + current lag only\n",
    "    feature_cols =  [current_lag] + base_feature_cols\n",
    "    \n",
    "    X = df_scaled[feature_cols]\n",
    "    y = df_scaled['target_scaled']\n",
    "\n",
    "    # Train-validation-test split (70-15-15), no shuffle\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "    \n",
    "    # Initialize Lasso\n",
    "    model = Lasso(alpha=0.1)\n",
    "    \n",
    "    # Train model and time\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Predictions\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate on validation\n",
    "    val_mae, val_rmse, val_r2, val_dae, val_lower = evaluate(y_val, y_val_pred)\n",
    "    # Evaluate on test\n",
    "    test_mae, test_rmse, test_r2, test_dae, test_lower = evaluate(y_test, y_test_pred)\n",
    "    \n",
    "    # Save results\n",
    "    results.append({\n",
    "        'Lookback (days)': lookback,\n",
    "        'Training Time (s)': round(training_time, 4),\n",
    "        \n",
    "        'Val MAE': round(val_mae, 4),\n",
    "        'Val RMSE': round(val_rmse, 4),\n",
    "        'Val R2': round(val_r2, 4),\n",
    "        'Val DAE': round(val_dae, 4),\n",
    "        'Val Lower Predictions %': round(val_lower, 2),\n",
    "        \n",
    "        'Test MAE': round(test_mae, 4),\n",
    "        'Test RMSE': round(test_rmse, 4),\n",
    "        'Test R2': round(test_r2, 4),\n",
    "        'Test DAE': round(test_dae, 4),\n",
    "        'Test Lower Predictions %': round(test_lower, 2),\n",
    "    })\n",
    "    print(f\"\\n% Validation Results (Lookback: {lookback} days)\")\n",
    "    print(f\" & {lookback} & {val_mae:.2f} & {val_dae:.2f} & {1:.2f} & {val_rmse:.2f} & {val_r2:.2f} & {val_lower:.2f} \\\\\\\\\")\n",
    "\n",
    "    # Print LaTeX table rows for Test results\n",
    "    print(f\"% Test Results (Lookback: {lookback} days)\")\n",
    "    print(f\" & {lookback} & {test_mae:.2f} & {test_dae:.2f} & {1:.2f} & {test_rmse:.2f} & {test_r2:.2f} & {test_lower:.2f} \\\\\\\\\")\n",
    "\n",
    "    # Feature importances (non-zero Lasso coefficients)\n",
    "    coefs = model.coef_\n",
    "    nonzero_features = [(feature, coef) for feature, coef in zip(X_train.columns, coefs) if coef != 0]\n",
    "\n",
    "    # # Print for in Overleaf\n",
    "    # print(f\"\\nNon-zero coefficients (Lookback: {lookback} days):\")\n",
    "    # for feature, coef in sorted(nonzero_features, key=lambda x: abs(x[1]), reverse=True):\n",
    "    #     print(f\"{feature}: {coef:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb9f23c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Results:\n",
      "   Lookback (days)  Training Time (s)  Val MAE  Val RMSE  Val R2  Val DAE  \\\n",
      "0                7             0.1922   0.0609    0.1014  0.7527   0.6683   \n",
      "1               30             0.2165   0.0677    0.1062  0.7288   0.6397   \n",
      "2               60             0.2158   0.0674    0.1056  0.7318   0.6531   \n",
      "3               90             0.2089   0.0676    0.1046  0.7371   0.6519   \n",
      "\n",
      "   Val Lower Predictions %  Test MAE  Test RMSE  Test R2  Test DAE  \\\n",
      "0                    41.72    0.0702     0.1066   0.7566    0.6303   \n",
      "1                    42.60    0.0761     0.1108   0.7371    0.6112   \n",
      "2                    41.87    0.0761     0.1102   0.7398    0.6241   \n",
      "3                    39.73    0.0753     0.1086   0.7475    0.6259   \n",
      "\n",
      "   Test Lower Predictions %  \n",
      "0                     40.53  \n",
      "1                     41.16  \n",
      "2                     38.93  \n",
      "3                     36.60  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSummary Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84914555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-zero coefficients (Lookback: 90 days):\n",
      "price_lag14d: 0.0013\n",
      "price_lag1d: 0.0008\n",
      "ema_22h: 0.0007\n",
      "price_lag90d: 0.0002\n",
      "ema_168h: -0.0002\n",
      "GlobHor (W/m²): -0.0000\n",
      "EArray (kW): 0.0000\n",
      "E_Grid (kW): -0.0000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b62d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(y_test,y_test_pred,df, 'month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7926028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(y_val, y_val_pred, y_test, y_test_pred, X_val, X_test, plot_fig=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277f0cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcd5fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d98a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
